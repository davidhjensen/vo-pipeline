{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9bbe16fc",
   "metadata": {},
   "source": [
    "# VO Pipeline\n",
    "Vision Algorithms for Mobile Robotics | Fall 2025 <br>\n",
    "David Jensen, Alessandro Pirini, Matteo Rubini"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e4c5494",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5787b350",
   "metadata": {},
   "source": [
    "### Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b18998a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "\n",
    "import cv2\n",
    "import skimage\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d839c4c9",
   "metadata": {},
   "source": [
    "### Data\n",
    "_Ensure that all datasets have been downloaded and unzipped into their respective folders_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fa422c92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define dataset paths\n",
    "# (Set these variables before running)\n",
    "kitti_path = \"kitti/kitti05/kitti\"\n",
    "malaga_path = \"malaga/malaga-urban-dataset-extract-07\"\n",
    "parking_path = \"parking/parking\"\n",
    "# own_dataset_path = \"/path/to/own_dataset\"\n",
    "\n",
    "if DATASET == 0:\n",
    "    assert 'kitti_path' in locals(), \"You must define kitti_path\"\n",
    "    img_dir = os.path.join(kitti_path, '05/image_0')\n",
    "    images = glob(os.path.join(img_dir, '*.png'))\n",
    "    last_frame = 4540\n",
    "    K = np.array([\n",
    "        [7.18856e+02, 0, 6.071928e+02],\n",
    "        [0, 7.18856e+02, 1.852157e+02],\n",
    "        [0, 0, 1]\n",
    "    ])\n",
    "    ground_truth = np.loadtxt(os.path.join(kitti_path, 'poses', '05.txt'))\n",
    "    ground_truth = ground_truth[:, [-9, -1]]  # same as MATLAB(:, [end-8 end])\n",
    "elif DATASET == 1:\n",
    "    assert 'malaga_path' in locals(), \"You must define malaga_path\"\n",
    "    img_dir = os.path.join(malaga_path, 'malaga-urban-dataset-extract-07_rectified_800x600_Images')\n",
    "    images = sorted(glob(os.path.join(img_dir, '*.png')))\n",
    "    last_frame = len(images)\n",
    "    K = np.array([\n",
    "        [621.18428, 0, 404.0076],\n",
    "        [0, 621.18428, 309.05989],\n",
    "        [0, 0, 1]\n",
    "    ])\n",
    "elif DATASET == 2:\n",
    "    assert 'parking_path' in locals(), \"You must define parking_path\"\n",
    "    img_dir = os.path.join(kitti_path, '05/image_0')\n",
    "    images = glob(os.path.join(img_dir, '*.png'))\n",
    "    last_frame = 598\n",
    "    K = np.loadtxt(os.path.join(parking_path, 'K.txt'), delimiter=\",\", usecols=(0, 1, 2))\n",
    "    ground_truth = np.loadtxt(os.path.join(parking_path, 'poses.txt'))\n",
    "    ground_truth = ground_truth[:, [-9, -1]]\n",
    "elif DATASET == 3:\n",
    "    # Own Dataset\n",
    "    # TODO: define your own dataset and load K obtained from calibration of own camera\n",
    "    assert 'own_dataset_path' in locals(), \"You must define own_dataset_path\"\n",
    "\n",
    "else:\n",
    "    raise ValueError(\"Invalid dataset index\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c0cdc90",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abe4c0a3",
   "metadata": {},
   "source": [
    "### Paramaters for all datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cf3ebdbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset -> 0: KITTI, 1: Malaga, 2: Parking, 3: Own Dataset\n",
    "DATASET = 0\n",
    "\n",
    "# Next keyframe to use for bootstrapping\n",
    "KITTI_BS_KF = 5\n",
    "MALAGA_BS_KF = 5\n",
    "PARKING_BS_KF = 5\n",
    "CUSTOM_BS_KF = 5\n",
    "\n",
    "# Number of rows and columns to divide image into for feature detection\n",
    "KITTI_ST_ROWS, KITTI_ST_COLS = 2, 4\n",
    "MALAGA_ST_ROWS, MALAGA_ST_COLS = 2, 4\n",
    "PARKING_ST_ROWS, PARKING_ST_COLS = 2, 4\n",
    "CUSTOM_ST_ROWS, CUSTOM_ST_COLS = 2, 4\n",
    "\n",
    "# Paramaters for Shi-Tomasi corners\n",
    "feature_params = dict( maxCorners = 100,\n",
    "                       qualityLevel = 0.3,\n",
    "                       minDistance = 7,\n",
    "                       blockSize = 7 )\n",
    "\n",
    "# Parameters for LKT\n",
    "lk_params = dict( winSize  = (15, 15),\n",
    "                  maxLevel = 2,\n",
    "                  criteria = (cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 10, 0.03))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4b09283",
   "metadata": {},
   "source": [
    "### Set parameters for specific datasets\n",
    "_Updates all parameters based on dataset being used_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "afcc4c2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_feature_masks(img_path, rows, cols) -> list[np.ndarray]:\n",
    "    # get image shape\n",
    "    img = cv2.imread(img_path)\n",
    "    H, W = img.shape[:2]\n",
    "\n",
    "    # get boundries of the cells\n",
    "    row_boundries = np.linspace(0, H, rows + 1, dtype=int)\n",
    "    col_boundries = np.linspace(0, W, cols + 1, dtype=int)\n",
    "\n",
    "    # create masks\n",
    "    masks = []\n",
    "    for row in range(rows):\n",
    "        for col in range(cols):\n",
    "            mask = np.zeros_like(img, dtype=bool)\n",
    "            r_s, r_e = row_boundries[[row, row + 1]]\n",
    "            c_s, c_e = col_boundries[[col, col + 1]]\n",
    "            mask[r_s:r_e, c_s:c_e] = True\n",
    "            masks.append(mask)\n",
    "            \n",
    "            # visulaization\n",
    "            # vis = np.zeros_like(img)\n",
    "            # vis[mask] = img[mask]\n",
    "            # cv2.imshow(\"masked\", vis)\n",
    "            # cv2.waitKey(0)\n",
    "            # cv2.destroyAllWindows()\n",
    "\n",
    "    return masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e148f240",
   "metadata": {},
   "outputs": [],
   "source": [
    "bs_kf_1: str # path to first keyframe used for bootstrapping dataset\n",
    "bs_kf_2: str # path to second keyframe used for bootstrapping dataset\n",
    "feature_masks: list[np.ndarray] # mask image into regions for feature tracking \n",
    "\n",
    "if DATASET == 0:\n",
    "    assert 'kitti_path' in locals(), \"You must define kitti_path\"\n",
    "    bs_kf_1 = images[0]\n",
    "    bs_kf_2 = images[KITTI_BS_KF]\n",
    "    feature_masks = get_feature_masks(bs_kf_1, KITTI_ST_ROWS, KITTI_ST_COLS)\n",
    "\n",
    "elif DATASET == 1:\n",
    "    assert 'malaga_path' in locals(), \"You must define malaga_path\"\n",
    "    bs_kf_1 = images[0]\n",
    "    bs_kf_2 = images[MALAGA_BS_KF]\n",
    "    feature_masks = get_feature_masks(bs_kf_1, MALAGA_ST_ROWS, MALAGA_ST_COLS)\n",
    "\n",
    "elif DATASET == 2:\n",
    "    assert 'parking_path' in locals(), \"You must define parking_path\"\n",
    "    img_dir = os.path.join(kitti_path, '05/image_0')\n",
    "    images = glob(os.path.join(img_dir, '*.png'))\n",
    "    bs_kf_1 = images[0]\n",
    "    bs_kf_2 = images[PARKING_BS_KF]\n",
    "    feature_masks = get_feature_masks(bs_kf_1, PARKING_ST_ROWS, PARKING_ST_COLS)\n",
    "\n",
    "elif DATASET == 3:\n",
    "    # Own Dataset\n",
    "    # TODO: define your own dataset and load K obtained from calibration of own camera\n",
    "    assert 'own_dataset_path' in locals(), \"You must define own_dataset_path\"\n",
    "\n",
    "else:\n",
    "    raise ValueError(\"Invalid dataset index\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02a0dc41",
   "metadata": {},
   "source": [
    "# Initialization\n",
    "- Select two keyframes with large enough baseline\n",
    "- Use indirect (feature-based) or direct (KLT) method to establish keypoint corrispondences between frames\n",
    "- Estimate relative pose and triangulate points to bootstrap point cloud (5-pt RANSAC)\n",
    "- Initialize VO pipeline with inlier keypoints and their associated landmarks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c861e643",
   "metadata": {},
   "source": [
    "### Corners"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6e4f96f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in images as greyscale\n",
    "img_bs_kf_1 = cv2.imread(bs_kf_1, 0)\n",
    "img_bs_kf_2 = cv2.imread(bs_kf_2, 0)\n",
    "\n",
    "st_corners_kf_1 = cv2.goodFeaturesToTrack(img_bs_kf_1, mask = None, **feature_params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a2b44f81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 703.,  120.]],\n",
       "\n",
       "       [[ 917.,  102.]],\n",
       "\n",
       "       [[ 928.,  109.]],\n",
       "\n",
       "       [[1086.,   79.]],\n",
       "\n",
       "       [[1081.,   86.]],\n",
       "\n",
       "       [[ 534.,  177.]],\n",
       "\n",
       "       [[ 896.,   91.]],\n",
       "\n",
       "       [[ 509.,  180.]],\n",
       "\n",
       "       [[ 929.,   96.]],\n",
       "\n",
       "       [[ 360.,  176.]],\n",
       "\n",
       "       [[ 726.,  124.]],\n",
       "\n",
       "       [[ 850.,   29.]],\n",
       "\n",
       "       [[ 926.,  137.]],\n",
       "\n",
       "       [[ 917.,   88.]],\n",
       "\n",
       "       [[ 467.,  173.]],\n",
       "\n",
       "       [[ 517.,  186.]],\n",
       "\n",
       "       [[ 359.,  169.]],\n",
       "\n",
       "       [[ 852.,  107.]],\n",
       "\n",
       "       [[ 544.,  169.]],\n",
       "\n",
       "       [[ 458.,  184.]],\n",
       "\n",
       "       [[ 479.,  179.]],\n",
       "\n",
       "       [[ 472.,  196.]],\n",
       "\n",
       "       [[1042.,   92.]],\n",
       "\n",
       "       [[ 926.,   81.]],\n",
       "\n",
       "       [[ 871.,  101.]],\n",
       "\n",
       "       [[ 935.,   76.]],\n",
       "\n",
       "       [[ 924.,  102.]],\n",
       "\n",
       "       [[ 856.,   71.]],\n",
       "\n",
       "       [[ 782.,  119.]],\n",
       "\n",
       "       [[ 729.,  142.]],\n",
       "\n",
       "       [[ 896.,  100.]],\n",
       "\n",
       "       [[ 287.,  189.]],\n",
       "\n",
       "       [[ 207.,  220.]],\n",
       "\n",
       "       [[ 852.,  136.]],\n",
       "\n",
       "       [[1022.,   59.]],\n",
       "\n",
       "       [[ 928.,  127.]],\n",
       "\n",
       "       [[ 461.,  200.]],\n",
       "\n",
       "       [[ 994.,   60.]],\n",
       "\n",
       "       [[ 918.,  117.]],\n",
       "\n",
       "       [[1044.,  105.]],\n",
       "\n",
       "       [[ 934.,  113.]],\n",
       "\n",
       "       [[ 517.,  179.]],\n",
       "\n",
       "       [[ 850.,   93.]],\n",
       "\n",
       "       [[ 904.,   76.]],\n",
       "\n",
       "       [[ 851.,  127.]],\n",
       "\n",
       "       [[ 416.,  173.]],\n",
       "\n",
       "       [[ 286.,  179.]],\n",
       "\n",
       "       [[ 921.,  131.]],\n",
       "\n",
       "       [[ 537.,  169.]],\n",
       "\n",
       "       [[ 243.,  174.]],\n",
       "\n",
       "       [[ 478.,  170.]],\n",
       "\n",
       "       [[ 913.,   22.]],\n",
       "\n",
       "       [[ 398.,  179.]],\n",
       "\n",
       "       [[ 349.,  176.]],\n",
       "\n",
       "       [[1084.,  103.]],\n",
       "\n",
       "       [[ 918.,  124.]],\n",
       "\n",
       "       [[ 882.,   94.]],\n",
       "\n",
       "       [[ 486.,  167.]],\n",
       "\n",
       "       [[ 318.,  189.]],\n",
       "\n",
       "       [[ 923.,   67.]],\n",
       "\n",
       "       [[ 481.,  193.]],\n",
       "\n",
       "       [[ 277.,  179.]],\n",
       "\n",
       "       [[ 429.,  178.]],\n",
       "\n",
       "       [[ 847.,  101.]],\n",
       "\n",
       "       [[ 399.,  186.]],\n",
       "\n",
       "       [[ 979.,   90.]],\n",
       "\n",
       "       [[ 498.,  189.]],\n",
       "\n",
       "       [[ 239.,  181.]],\n",
       "\n",
       "       [[1111.,   55.]],\n",
       "\n",
       "       [[ 864.,   81.]],\n",
       "\n",
       "       [[ 924.,   21.]],\n",
       "\n",
       "       [[ 219.,  180.]],\n",
       "\n",
       "       [[ 917.,   81.]],\n",
       "\n",
       "       [[ 319.,  179.]],\n",
       "\n",
       "       [[ 657.,  192.]],\n",
       "\n",
       "       [[ 423.,  173.]],\n",
       "\n",
       "       [[1106.,   79.]],\n",
       "\n",
       "       [[ 180.,  182.]],\n",
       "\n",
       "       [[ 847.,   73.]],\n",
       "\n",
       "       [[1128.,   49.]],\n",
       "\n",
       "       [[ 934.,   91.]],\n",
       "\n",
       "       [[ 268.,  179.]],\n",
       "\n",
       "       [[ 763.,  141.]],\n",
       "\n",
       "       [[ 217.,  157.]],\n",
       "\n",
       "       [[1100.,   92.]],\n",
       "\n",
       "       [[ 591.,  164.]],\n",
       "\n",
       "       [[ 481.,  126.]],\n",
       "\n",
       "       [[ 933.,  103.]],\n",
       "\n",
       "       [[ 118.,  110.]],\n",
       "\n",
       "       [[ 461.,  126.]],\n",
       "\n",
       "       [[ 470.,  183.]],\n",
       "\n",
       "       [[ 344.,  185.]],\n",
       "\n",
       "       [[ 429.,  202.]],\n",
       "\n",
       "       [[ 657.,  161.]],\n",
       "\n",
       "       [[ 201.,  114.]],\n",
       "\n",
       "       [[ 455.,  193.]],\n",
       "\n",
       "       [[ 865.,   92.]],\n",
       "\n",
       "       [[1128.,   56.]],\n",
       "\n",
       "       [[ 210.,  157.]],\n",
       "\n",
       "       [[ 325.,  188.]]], dtype=float32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "st_corners_kf_1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb197d59",
   "metadata": {},
   "source": [
    "### Keypoint corrsipondences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "921a48cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# KLT here maybe using itermediate frames\n",
    "cv2."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84f86f87",
   "metadata": {},
   "source": [
    "# Operation\n",
    "- Match keypoints in current image to existing landmarks\n",
    "    - Extract keypoints (Harris)\n",
    "    - Track (KLT)\n",
    "- Estimate pose\n",
    "    - Estimate pose and handle outliers (P3P plus RANSAC)\n",
    "- Add new landmarks as needed by triangulating new features\n",
    "    - Keep track of candidate landmarks\n",
    "        - Keypoint itself\n",
    "        - Observation when first seen\n",
    "        - Pose when first seen\n",
    "    - Only add when they have been tracked for long enough and baselineis large enough\n",
    "    - Discard if track fails\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vo_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
